{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step One: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Two: Initialize OpenAI and ChromaDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI(\n",
    "            base_url=\"https://openai.vocareum.com/v1\",\n",
    "            api_key=\"voc-1731846060126677132371766c7b06ddc2849.94786379\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(\n",
    "            path= \"/workspace/Project/\",\n",
    "            settings=Settings(\n",
    "                anonymized_telemetry=False,  # Disable telemetry for privacy\n",
    "                allow_reset=True             # Allow database reset for development\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Three: Create Collection in chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection(name=documents)\n"
     ]
    }
   ],
   "source": [
    "def create_collection(collection_name : str) -> chromadb.Collection:\n",
    "    if collection_name == \"documents\":\n",
    "        client.delete_collection(collection_name)\n",
    "    \n",
    "    collection = client.create_collection(\n",
    "                    name=collection_name,\n",
    "                    embedding_function=None,  # We'll handle embeddings manually\n",
    "                )\n",
    "    return collection\n",
    "collection = create_collection(\"documents\")\n",
    "print(collection)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Four: Chunk Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '0', 'chunk': 'CONVENTION:\\nUse camelCase for all variable names.\\n\\nCORRECT:\\nuserName = \"John\"\\ntotalCount = 0\\n\\nINCORRECT:\\nuser_name = \"John\"\\ntotal_count = 0\\n\\nREASON:\\nMaintains consistency across the codebase and follows Google Java Style.', 'metadata': {'rule_id': 'naming_variables', 'category': 'naming', 'severity': 'error | warning | suggestion'}}, {'id': '1', 'chunk': 'CONVENTION:\\nUse CamelCase for all class names.\\n\\nCORRECT:\\npublic class ClassName\\nclass OtherClassName\\n\\nINCORRECT:\\npublic class Class_Name\\nclass Other_Class_Name\\n\\nREASON:\\nMaintains consistency across the codebase and follows Google Java Style.', 'metadata': {'rule_id': 'naming_classes', 'category': 'naming', 'severity': 'error | warning | suggestion'}}, {'id': '2', 'chunk': 'CONVENTION:\\nUse CamelCase for all interface names.\\n\\nCORRECT:\\npublic interface InterfaceName\\ninterface OtherInterfaceName\\n\\nINCORRECT:\\npublic class Interface_Name\\nclass Other_Interface_Name\\n\\nREASON:\\nMaintains consistency across the codebase and follows Google Java Style.', 'metadata': {'rule_id': 'naming_interfaces', 'category': 'naming', 'severity': 'error | warning | suggestion'}}, {'id': '3', 'chunk': 'CONVENTION:\\nUser Use CamelCase for all method names.\\n\\nCORRECT:\\npublic void addResource() {\\n    //...\\n}\\n\\nINCORRECT:\\npublic void add_resource{\\n    //...\\n}\\n\\nREASON:\\nMaintains consistency across the codebase and follows Google Java Style.', 'metadata': {'rule_id': 'method_naming', 'category': 'naming', 'severity': 'warning'}}, {'id': '4', 'chunk': 'CONVENTION:\\nController class must:\\n1. End with \"Contorller\"\\n2. @Controller annotation must be used\\n\\nCORRECT:\\n@Controller\\npublic class UserController{\\n    //...\\n}\\n\\nINCORRECT:\\n//Missing annotation\\npublic class UserController{\\n    //...\\n}\\n\\n//Wrong naming\\n@Controller\\npublic class User{\\n    //...\\n}\\n\\nREASON:\\nEnsures Spring framework recognizes controllers and maintains naming consistency.', 'metadata': {'rule_id': 'controller_naming', 'category': 'class_definition', 'severity': 'error | warning'}}, {'id': '5', 'chunk': 'CONVENTION:\\nService interface must:\\nEnd with \"Service\"\\n\\nCORRECT:\\npublic interface UserService{\\n    //...\\n}\\n\\nINCORRECT:\\n//Wrong naming\\npublic class User{\\n    //...\\n}\\n\\nREASON:\\nEnsures Spring framework recognizes controllers and maintains naming consistency.', 'metadata': {'rule_id': 'service_naming', 'category': 'interface_definition', 'severity': 'error | warning'}}, {'id': '6', 'chunk': 'CONVENTION:\\nService class must:\\n1. End with \"ServiceImpl\"\\n2. @Service annotation must be used\\n\\nCORRECT:\\n@Service\\npublic class UserServiceImpl{\\n    //...\\n}\\n\\nINCORRECT:\\n//Missing annotation\\npublic class UserServiceImpl{\\n    //...\\n}\\n\\n//Wrong naming\\n@Service\\npublic class User{\\n    //...\\n}\\n\\nREASON:\\nEnsures Spring framework recognizes controllers and maintains naming consistency.', 'metadata': {'rule_id': 'service_impl_naming', 'category': 'class_definition', 'severity': 'error | warning'}}, {'id': '7', 'chunk': 'CONVENTION:\\nService interface must:\\nEnd with \"Repository\"\\n\\nCORRECT:\\npublic interface UserRepository{\\n    //...\\n}\\n\\nINCORRECT:\\npublic class User{\\n    //...\\n}\\n\\nREASON:\\nEnsures Spring framework recognizes controllers and maintains naming consistency.', 'metadata': {'rule_id': 'repository_naming', 'category': 'interface_definition', 'severity': 'error | warning'}}, {'id': '8', 'chunk': 'CONVENTION:\\nService class must:\\n1. End with \"RepositoryImpl\"\\n2. @Repository annotation must be used\\n\\nCORRECT:\\n@Repository\\npublic class UserRepositoryImpl{\\n    //...\\n}\\n\\nINCORRECT:\\n//Missing annotation\\npublic class UserRepositoryImpl{\\n    //...\\n}\\n\\n//Wrong naming\\n@Repository\\npublic class User{\\n    //...\\n}\\n\\nREASON:\\nEnsures Spring framework recognizes controllers and maintains naming consistency.', 'metadata': {'rule_id': 'repository_impl_naming', 'category': 'class_definition', 'severity': 'error | warning'}}, {'id': '9', 'chunk': 'CONVENTION:\\n1. service classes must implement service interface having the same name\\n2. repository classes must implement repository interface having the same name \\n\\nCORRECT:\\n1. public interface UserService{\\n    //...\\n}\\n@service\\npublic class UserServiceImpl implements UserService{\\n    //...\\n}\\n\\n2. public interface UserRepository{\\n    //...\\n}\\n@Repository\\npublic class UserRepositoryImpl implements UserRepository{\\n    //...\\n}\\n\\n\\nINCORRECT:\\n1. public interface EmployeeService{\\n    //...\\n}\\n@Service\\npublic class UserServiceImpl implements EmployeeService{\\n    //...\\n}\\n\\n2. public interface EmployeeRepositroy {\\n    //...\\n}\\n@Repository\\npublic class UserRepositoryImpl implements EmployeeRepositroy {\\n    //...\\n}', 'metadata': {'rule_id': 'cglib', 'category': 'proxy_definition', 'severity': 'error | warning | suggestion'}}]\n"
     ]
    }
   ],
   "source": [
    "def chunk_text(file_path: Path) -> tuple[list[str], list[Dict[str, Any]]]: \n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    rules = text.split(\"----------------------------------------------\")\n",
    "    documents : list[Dict] = []\n",
    "\n",
    "    index = 0\n",
    "    for rule in rules:\n",
    "        if not rule:\n",
    "            break\n",
    "\n",
    "        rule_id = None\n",
    "        category = None\n",
    "        severity = None\n",
    "\n",
    "        for line in rule.split(\"\\n\"):\n",
    "            if line.startswith(\"[RULE_ID:\"):\n",
    "                rule_id = line.split(\":\")[1].strip(\"]\").strip()\n",
    "            elif line.startswith(\"[CATEGORY\"):\n",
    "                category = line.split(\":\")[1].strip(\"]\").strip()\n",
    "            elif line.startswith(\"[SEVERITY:\"):\n",
    "                severity = line.split(\":\")[1].strip(\"]\").strip()\n",
    "        \n",
    "        chunk = re.sub(r\"\\[.*?\\]\\s*\", \"\", rule).strip()\n",
    "        metadata = {\n",
    "            \"rule_id\" : rule_id,\n",
    "            \"category\" : category,\n",
    "            \"severity\" : severity\n",
    "        }\n",
    "\n",
    "        documents.append({\n",
    "            \"id\" : str(index),\n",
    "            \"chunk\" : chunk,\n",
    "            \"metadata\" : metadata\n",
    "        })\n",
    "\n",
    "        index += 1\n",
    "        \n",
    "    return documents\n",
    "\n",
    "documents = chunk_text(\"/workspace/Project/conventions_document.txt\")\n",
    "print(documents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Five: Generate Embeddings for Chnuks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(chunks : list[str]) -> List[List[float]]:\n",
    "    response = openai_client.embeddings.create(\n",
    "                    model = \"text-embedding-3-small\",\n",
    "                    input = chunks\n",
    "                )\n",
    "    embeddings = [embedding.embedding for embedding in response.data]\n",
    "    return embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Six: Add Chunks, Embeddings and Metadatas to Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_collection(documents : list[Dict]):\n",
    "\n",
    "    ids = [document[\"id\"] for document in documents]\n",
    "    chunks = [document[\"chunk\"] for document in documents]\n",
    "    embeddings = generate_embedding(chunks)\n",
    "    metadatas = [document[\"metadata\"] for document in documents]\n",
    "\n",
    "    collection.add(\n",
    "        ids=ids,\n",
    "        documents=chunks,\n",
    "        embeddings=embeddings,\n",
    "        metadatas=metadatas,\n",
    "    )\n",
    "\n",
    "add_to_collection(documents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Seven: Search Documents (Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documents(query: str, n_context: int = 9, metadata_filter: Optional[Dict] = None):\n",
    "    if metadata_filter:\n",
    "        print(\"metadata filters: \", metadata_filter)\n",
    "\n",
    "    query_embeddings = generate_embedding([query])\n",
    "\n",
    "    results = collection.query(\n",
    "                query_embeddings=query_embeddings,\n",
    "                n_results=n_context,\n",
    "                where=metadata_filter,\n",
    "                include=[\"documents\", \"distances\", \"metadatas\"]\n",
    "            )\n",
    "\n",
    "    formatted_results = {\n",
    "        \"query\": query,\n",
    "        \"n_results\": len(results['documents'][0]),\n",
    "        \"results\": []\n",
    "    }\n",
    "    for i in range(len(results['documents'][0])):\n",
    "        formatted_results[\"results\"].append({\n",
    "            \"document\": results['documents'][0][i],\n",
    "            \"similarity_score\": 1 - results['distances'][0][i],  # Convert distance to similarity\n",
    "            \"metadata\": results['metadatas'][0][i]\n",
    "    })\n",
    "\n",
    "    return formatted_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_llm_response(query: str, n_context: int = 9):\n",
    "\n",
    "    search_results = search_documents(query, n_context)\n",
    "        \n",
    "    if not search_results[\"results\"]:\n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"answer\": \"I couldn't find relevant information to answer your question.\",\n",
    "            \"context\": [],\n",
    "            \"generation_time\": 0,\n",
    "            \"context_used\": 0\n",
    "        }\n",
    "\n",
    "    context_documents = []\n",
    "    for result in search_results[\"results\"]:\n",
    "        context_documents.append({\n",
    "            \"content\": result[\"document\"],\n",
    "            \"similarity\": result[\"similarity_score\"],\n",
    "            \"rule_id\": result[\"metadata\"].get(\"rule_id\", \"Unknown\")\n",
    "        })\n",
    "\n",
    "    context_text = \"\\n\\n\".join([\n",
    "            f\"Document {doc[\"rule_id\"]} (Similarity: {doc['similarity']:.3f}):\\n{doc['content']}\"\n",
    "            for i, doc in enumerate(context_documents)\n",
    "        ])\n",
    "\n",
    "    prompt = f\"\"\"Based on the following context documents, please check user's java code convention, If context has no information mention that it not provided from context.\n",
    "\n",
    "        Context Documents:\n",
    "        {context_text}\n",
    "\n",
    "        User Question: {query}\n",
    "\n",
    "        Please provide a comprehensive answer based on the context provided:\"\"\"\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7,\n",
    "        max_completion_tokens=500\n",
    "    )\n",
    "\n",
    "    llm_response = {\n",
    "                \"query\": query,\n",
    "                \"answer\": response.choices[0].message.content,\n",
    "                \"context\": context_documents,\n",
    "                \"context_used\": len(context_documents),\n",
    "            }\n",
    "\n",
    "    return llm_response\n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "    @Service\n",
    "    public class UserServiceImpl implements UserService {\n",
    "        //...\n",
    "    }\n",
    "\n",
    "    \"\"\"\n",
    "llm_response = generate_llm_response(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context documents provided, your Java code convention for the class `UserServiceImpl` is correct. Here are the specific points that align with the conventions outlined in the documents:\n",
      "\n",
      "1. **Naming Convention for Service Implementation**:\n",
      "   - Your class `UserServiceImpl` correctly ends with \"ServiceImpl\", which aligns with the convention stated in the document `service_impl_naming`.\n",
      "\n",
      "2. **Annotation Usage**:\n",
      "   - You have correctly used the `@Service` annotation, which is required as per the same document.\n",
      "\n",
      "3. **Interface Implementation**:\n",
      "   - Your class implements the `UserService` interface. The context does not directly specify a convention regarding interface names, but it is generally accepted that service classes should implement service interfaces of the same name.\n",
      "\n",
      "Overall, your code adheres to the conventions provided in the context documents. No issues were found regarding naming or annotation usage.\n"
     ]
    }
   ],
   "source": [
    "print(llm_response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23393d2575091a37cff0d0e9e7479591a295495b26c3b2ebf9b64da572e02d85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
